{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the k0rdent docs","text":""},{"location":"#introduction","title":"Introduction","text":"<p>k0rdent is focused on developing a consistent way to deploy and manage Kubernetes clusters at scale. One way to think of k0rdent is as a \"super control plane\" designed to manage other Kubernetes control planes. Another way to think of k0rdent is as a platform for Platform Engineering. If you are building an internal developer platform (IDP), need a way to manage Kubernetes clusters at scale in a centralized place, create Golden Paths, etc. k0rdent is a great way to do that.</p> <p>Whether you want to manage Kubernetes clusters on-premises, in the cloud, or a combination of both, k0rdent provides a consistent way to do so. With full life-cycle management, including provisioning, configuration, and maintenance, k0rdent is designed to be a repeatable and secure way to manage your Kubernetes clusters in a central location.</p>"},{"location":"#k0rdent-vs-project-2a-vs-hmc-naming","title":"k0rdent vs Project 2A vs HMC naming","text":"<p>k0rdent is the official name of an internal Mirantis project that was originally codenamed \"Project 2A\". During our initial skunkworks-style 3-month MVP push, the code was put into a repository named HMC, which stood for \"Hybrid Multi-Cluster Controller\". What is HMC became k0rdent Cluster Manager (kcm), but it may be a little confusing because the overall project was still called \"Project 2A\" or even \"HMC\" at times.</p> <p>So, to be clear, here are the names and components:</p> <ul> <li>k0rdent: the overall project name</li> <li>k0rdent Cluster Manager (kcm)</li> <li>k0rdent State Manager (ksm)<ul> <li>This is currently rolled into kcm, but will be split out in the   future</li> <li>ksm leverages Project Sveltos   for certain functionality</li> </ul> </li> <li>k0rdent Observability and FinOps (kof)</li> <li>Project 2A: the original codename of k0rdent (may occasionally show   up in some documentation)</li> <li>HMC or hmc: the original repository name for k0rdent and kcm   development (may occasionally show up in some documentation and code)</li> <li>motel: the original repository and codename for kof (may   occasionally show up in some documentation and code)</li> </ul>"},{"location":"#k0rdent-components","title":"k0rdent Components","text":"<p>The main components of k0rdent include:</p> <ul> <li> <p>k0rdent Cluster Manager (kcm)</p> <p>Deployment and life-cycle management of Kubernetes clusters, including configuration, updates, and other CRUD operations.</p> </li> <li> <p>k0rdent State Manager (ksm)</p> <p>Installation and life-cycle management of beach-head services, policy, Kubernetes API configurations and more.</p> </li> <li> <p>k0rdent Observability and FinOps (kof)</p> <p>Cluster and beach-head services monitoring, events and log management.</p> </li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<p>See the k0rdent Quick Start Guide.</p>"},{"location":"#supported-providers","title":"Supported Providers","text":"<p>k0rdent leverages the Cluster API provider ecosystem, the following providers have had <code>ProviderTemplates</code> created and validated, and more are in the works.</p> <ul> <li>AWS</li> <li>Azure</li> <li>vSphere</li> <li>OpenStack</li> </ul>"},{"location":"#development-documentation","title":"Development Documentation","text":"<p>Documentation related to development process and developer specific notes located in the main repository.</p>"},{"location":"guide_to_k0rdent_documentation/","title":"Guide to k0rdent documentation","text":"<p>k0rdent\u2019s documentation has five main parts:</p> <ul> <li> <p>Welcome to k0rdent: Go here to learn what k0rdent is all about, why we're building' it, and the basics of how it can be used, day to day.</p> <ul> <li> <p>Why k0rdent?: What k0rdent is, how it\u2019s different, and why you might use it.</p> </li> <li> <p>K0rdent Architecture: Just the basics: understanding k0rdent\u2019s components and how they work together.</p> </li> </ul> </li> <li> <p>QuickStarts and Tutorials: Go here if you\u2019re in a hurry.</p> <ul> <li>QuickStart 1 - k0rdent pre-requisites Installation basics</li> <li>QuickStart 2 - AWS infrastructure setup Setting up an AWS test environment for k0rdent</li> <li>QuickStart 3 - Deploy managed clusters on AWS Deploying with ClusterTemplates and ManagedCluster objects</li> <li>Tutorial 1 - Upgrade a Single Standalone Cluster</li> <li>Tutorial 2 - Install a ServiceTemplate into a single standalone cluster</li> <li>Tutorial 3 - Install a ServiceTemplate into multiple clusters</li> <li>Tutorial 4 - Approve a ClusterTemplate &amp; InfraCredentials for a separate namespace</li> <li>Tutorial 5 - Approve a ServiceTemplate for a separate namespace</li> <li>Tutorial 6 - Use an approved ClusterTemplate in a separate namespace</li> <li>Tutorial 7 - Use an approved ServiceTemplate in a separate namespace</li> </ul> </li> <li> <p>Reference Guides: Deeper references for using k0rdent with teams and in production.</p> <ul> <li> <p>Administrator Guide: Using k0rdent in production. This section is for CloudOps administrators who will be installing k0rdent and making it available to Project Teams who will use it to deploy applications.</p> </li> <li> <p>User Guide: Once k0rdent is in place, this guide helps Project Teams, developers, and other users leverage k0rdent securely and effectively.</p> </li> <li> <p>Template Reference Guide: k0rdent works on the basis of templates, describing platforms and infrastructures. This guide explains how k0rdent templates work and how to modify and create them.</p> </li> </ul> </li> <li> <p>Community: Who works on k0rdent, how to get involved, and how to contribute.</p> </li> </ul>"},{"location":"guide_to_quickstarts_and_tutorials/","title":"Guide to QuickStarts and Tutorials","text":"<p>The following is a recipe for quickly installing k0rdent on a small laptop Kubernetes cluster and experiencing how it works. Emphasis is on quick and simple, not production-ready. Setting up k0rdent for production is detailed in the Administrator Guide.</p> <p>Limitations and constraints \u2014 our Quickstart and subsequent Tutorials assume:</p> <ul> <li>You have access to a Linux laptop or VM running recent Ubuntu or another Debian distribution.</li> <li>You have administrative-level access to an Amazon Web Services account \u2014 Our QuickStart setup will use Amazon Web Services as target infrastructure and create k0s Kubernetes clusters on AWS EC2 virtual machines, and subsequent Tutorials will re-use this setup.</li> </ul> <p>Coming soon \u2014 QuickStarts and Tutorials for other Kubernetes distros, clouds, and environments k0rdent supports, including:</p> <ul> <li>AWS hosted \u2014 k0s Kubernetes on AWS virtual machines (this QuickStart)</li> <li>AWS EKS managed \u2014 Amazon Elastic Kubernetes Service </li> <li>Azure hosted \u2014 k0s Kubernetes on Azure virtual machines</li> <li>Azure AKS managed \u2014 Azure Kubernetes Service</li> <li>vSphere hosted \u2014 k0s Kubernetes on vSphere virtual machines</li> <li>OpenStack hosted \u2014 k0s Kubernetes on OpenStack virtual machines</li> </ul>"},{"location":"guide_to_quickstarts_and_tutorials/#quickstart","title":"QuickStart","text":"<p>Our QuickStart has three parts:</p> <ul> <li>QuickStart 1: k0rdent prerequisites \u2014 Here, we install pre-requisite applications, create a small laptop Kubernetes management cluster with KinD, clone the Getting Started repository and install it in the management cluster, and install k0rdent itself.</li> <li>QuickStart 2: AWS infrastructure setup \u2014 Here, we set up the AWS roles, policies, users, and credentials k0rdent and and CAPA (ClusterAPI for AWS) need.</li> <li>QuickStart 3: Deploy a managed cluster on AWS \u2014 Here, we deploy your first clusters on AWS. We'll actually be deploying two small clusters to start, so that in the tutorials, below, we can demonstrate how k0rdent can perform multi-cluster operations. In fact, k0rdent can, in principle, enable control of dozens, hundreds, or thousands of clusters, distributed across multiple clouds and infrastructures.</li> </ul>"},{"location":"guide_to_quickstarts_and_tutorials/#tutorials","title":"Tutorials","text":"<p>Once you've completed the QuickStart and deployed your first clusters on AWS, we re-use the same setup in additional Tutorials that walk you through important workflow steps for using k0rdent. These include:</p> <ul> <li>Tutorial 1 - Upgrade a Single Standalone Cluster \u2014 Apply a rolling upgrade to one of your newly-deployed clusters</li> <li>Tutorial 2 - Install a ServiceTemplate into a single standalone cluster \u2014 Add services to a cluster to create a more complete platform</li> <li>Tutorial 3 - Install a ServiceTemplate into multiple clusters \u2014 Leverage k0rdent to instantiate standardized platforms at scale</li> </ul> <p>Initial Tutorials focus on serving the needs of Platform Architects and Platform Engineering teams. They'll give you a feel of using k0rdent from first principles to define and instantiate Internal Development Platforms (IDPs) on clouds and infrastructure(s). </p>"},{"location":"guide_to_quickstarts_and_tutorials/#k0rdent-workflows","title":"k0rdent workflows","text":"<p>Large organizations also need means of working safely at scale \u2014 sharing innovative methods along 'golden paths,' enabling far-flung operations, keeping things simple and robust for innovation consumers (i.e., hiding complexity), and ensuring compliance, security, and standards. k0rdent is being engineered to enable at-scale operations much simpler. For example, Platform Architects can use k0rdent to define platform templates and approve these for use by others with conditional safeguards. Platform Leads and other authorized users can consume these templates (within constraints established by the Platform Architects) to create and lifecycle manage platforms for their own teams and stakeholders.</p> <p>Two tutorials demonstrate aspects of how k0rdent enables sharing for Platform Architects:</p> <ul> <li>Approve a ClusterTemplate &amp; InfraCredentials for a separate namespace (i.e., safely share a cluster template and credentials enabling its use without making the template modifiable or the relevant credentials readable)</li> <li>Approve a ServiceTemplate for a separate namespace (i.e., safely share a service template with others, while constraining how it can be used)</li> </ul> <p>Finally, two companion tutorials demonstrate how shared templates can be consumed (e.g., by Platform Leads) within appropriate guardrails.</p> <ul> <li>Use an approved ClusterTemplate in a separate namespace (e.g., to instantiate a cluster for your team)</li> <li>Use an approved ServiceTemplate in a separate namespace (e.g., to install services on such a cluster in a constrained way)</li> </ul> <p>Ready? Let's discover how to use k0rdent!</p>"},{"location":"k0rdent_architecture/","title":"k0rdent architecture","text":"<p>Text coming. Draft in GDocs. </p>"},{"location":"quickstart_1_k0rdent_prerequisites/","title":"QuickStart 1 - Install k0rdent prerequisites","text":"<p>The Quickstart installation has a couple of dependencies, so let\u2019s get them installed before we start. </p>"},{"location":"quickstart_1_k0rdent_prerequisites/#install-make","title":"Install make","text":"<p>We\u2019ll be using Makefiles to execute a lot of these instructions, so make sure that you have make installed:</p> <pre><code>sudo apt-get install make\n</code></pre>"},{"location":"quickstart_1_k0rdent_prerequisites/#install-docker","title":"Install Docker","text":"<p>Our k0rdent management cluster for this QuickStart will run on Kubernetes-in-Docker (KinD), so let\u2019s go ahead and get Docker installed if you don\u2019t have it already. You can find the full instructions here, but here\u2019s the short version:</p>"},{"location":"quickstart_1_k0rdent_prerequisites/#first-uninstall-older-potentially-conflicting-versions","title":"First uninstall older, potentially conflicting versions:","text":"<pre><code>for pkg in docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc; do sudo apt-get remove $pkg; done\n</code></pre>"},{"location":"quickstart_1_k0rdent_prerequisites/#use-the-docker-convenience-script-to-deploy-docker","title":"Use the Docker convenience script to deploy Docker:","text":"<pre><code>curl -fsSL https://get.docker.com -o get-docker.sh\nsudo sh get-docker.sh\n</code></pre>"},{"location":"quickstart_1_k0rdent_prerequisites/#install-kubectl","title":"Install kubectl","text":"<p>Our scripts will need the Kubernetes command line client. Full instructions for installing <code>kubectl</code> are here, but assuming you\u2019re on an x86 machine, the basic instructions are:</p> <pre><code>curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\nsudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\n</code></pre>"},{"location":"quickstart_1_k0rdent_prerequisites/#install-clusterawsadm","title":"Install clusterawsadm","text":"<p>k0rdent uses Cluster API (CAPI) to marshal clouds and infrastructures. For AWS, this means using the components from the Cluster API Provider AWS (CAPA) project. This QuickStart leverages <code>clusterawsadm</code>, a CLI tool created by CAPA project that helps with AWS-specific tasks like IAM role, policy, and credential configuration. To install <code>clusterawsadm</code> on Ubuntu on x86 hardware:</p> <pre><code>curl -LO https://github.com/kubernetes-sigs/cluster-api-provider-aws/releases/download/v2.7.1/clusterawsadm-linux-amd64\nsudo install -o root -g root -m 0755 clusterawsadm-linux-amd64 /usr/local/bin/clusterawsadm\n</code></pre>"},{"location":"quickstart_1_k0rdent_prerequisites/#install-jq","title":"Install jq","text":"<p>You\u2019ll need the <code>jq</code> utility to process JSON from kubectl. Among other things, this helps you monitor steps in the installation process:</p> <pre><code>sudo apt install jq\n</code></pre>"},{"location":"quickstart_1_k0rdent_prerequisites/#clone-the-getting-started-repo","title":"Clone the Getting Started repo","text":"<p>All the scripts required for our QuickStart and Tutorials are in the Getting Started repo at https://github.com/k0rdent/demos. Let's clone that repo:</p> <pre><code>git clone https://github.com/k0rdent/demos\ncd demos\n</code></pre>"},{"location":"quickstart_1_k0rdent_prerequisites/#create-the-management-cluster","title":"Create the management cluster","text":"<p>Now we\u2019re ready to create the k0rdent management cluster. The makefile (in 2a-demos) does the work. Because we\u2019re going to need to access Docker as root, let\u2019s go ahead and change over to root:</p> <pre><code>sudo su\n</code></pre> <p>Now go ahead and bootstrap the management cluster using KinD:</p> <pre><code>make bootstrap-kind-cluster\n</code></pre> <p>If you want to specify a particular name for this cluster, you can include it in an environment variable called <code>KIND_CLUSTER_NAME</code>:</p> <pre><code>export KIND_CLUSTER_NAME=k0rdentdemo\nsudo make bootstrap-kind-cluster\n</code></pre> <p>This command also sets up your <code>KUBECONFIG</code> and makes sure kubectl is pointing to the proper context:</p> <pre><code>No kind clusters found.\nCreating cluster \"hmc-management-local\" ...\n \u2713 Ensuring node image (kindest/node:v1.31.2) \ud83d\uddbc\n \u2713 Preparing nodes \ud83d\udce6\n \u2713 Writing configuration \ud83d\udcdc\n \u2713 Starting control-plane \ud83d\udd79\ufe0f\n \u2713 Installing CNI \ud83d\udd0c\n \u2713 Installing StorageClass \ud83d\udcbe\nSet kubectl context to \"kind-hmc-management-local\"\nYou can now use your cluster with:\nkubectl cluster-info --context kind-hmc-management-local\nHave a question, bug, or feature request? Let us know! https://kind.sigs.k8s.io/#community \ud83d\ude42\nSwitched to context \"kind-hmc-management-local\".\n</code></pre> <p>Once you see this output, you can confirm the cluster is running by issuing a kubectl command:</p> <pre><code>kubectl get pods --all-namespaces\nNAMESPACE            NAME                                                         READY   STATUS    RESTARTS   AGE\nkube-system          coredns-7c65d6cfc9-c9vg6                                     1/1     Running   0          107s\nkube-system          coredns-7c65d6cfc9-q7tds                                     1/1     Running   0          107s\nkube-system          etcd-hmc-management-local-control-plane                      1/1     Running   0          113s\nkube-system          kindnet-m98qq                                                1/1     Running   0          107s\nkube-system          kube-apiserver-hmc-management-local-control-plane            1/1     Running   0          113s\nkube-system          kube-controller-manager-hmc-management-local-control-plane   1/1     Running   0          113s\nkube-system          kube-proxy-vh4mw                                             1/1     Running   0          107s\nkube-system          kube-scheduler-hmc-management-local-control-plane            1/1     Running   0          114s\nlocal-path-storage   local-path-provisioner-57c5987fd4-4jdgf                      1/1     Running   0          107s\n</code></pre>"},{"location":"quickstart_1_k0rdent_prerequisites/#install-k0rdent-into-the-management-cluster","title":"Install k0rdent into the management cluster","text":"<p>You\u2019re finally ready to install k0rdent!  Fortunately, that\u2019s easy too:</p> <pre><code>make deploy-2a\n</code></pre> <p>The actual deployment can take 5 or 10 minutes, so you\u2019ll want to monitor the installation:</p> <pre><code>PATH=$PATH:./bin kubectl get management hmc -o go-template='{{range $key, $value := .status.components}}{{$key}}: {{if $value.success}}{{$value.success}}{{else}}{{$value.error}}{{end}}{{\"\\n\"}}{{end}}'\n</code></pre> <p>When k0rdent installation has succeeded, the output will look like this:</p> <pre><code>capi: true\ncluster-api-provider-aws: true\ncluster-api-provider-azure: true\ncluster-api-provider-vsphere: true\nhmc: true\nk0smotron: true\nprojectsveltos: true\n</code></pre>"},{"location":"quickstart_1_k0rdent_prerequisites/#install-the-getting-started-helm-repo-into-the-management-cluster","title":"Install the Getting Started Helm Repo into the management cluster","text":"<p>Helm charts for deploying the various Getting Started functions are in their own OCI repo, so let\u2019s get that set up on the management cluster:</p> <pre><code>make setup-helmrepo\n</code></pre> <p>As you can see, this makefile deploys a local OCI Helm registry and adds a HelmRepository resource to the cluster so we can use it to deploy the various objects such as child clusters and templates:</p> <pre><code>deployment.apps/helm-registry created\npersistentvolumeclaim/helm-registry-storage created\nservice/helm-registry created\nhelmrepository.source.toolkit.fluxcd.io/2a-demos created\nNow add the Helm charts with custom Cluster and Service Templates:\nmake push-helm-charts\n</code></pre> <p>Now all the pre-requisites are in place, we can move on to setting up to deploy managed clusters on AWS.</p>"},{"location":"quickstart_2_aws_infra_setup/","title":"QuickStart 2 - AWS infrastructure setup","text":"<p>For this next phase of the k0rdent QuickStart, you\u2019ll need the <code>clusterawsadm</code> tool (we installed this in QuickStart 1 - k0rdent prerequisites) and an AWS account with administrator permissions.</p>"},{"location":"quickstart_2_aws_infra_setup/#get-access-and-secret-keys-from-aws","title":"Get access and secret keys from AWS","text":"<p>You likely already have access and secret keys for your AWS account. But if you don't, we'll create them now. Start by logging into your admin account and click your name in the upper right-hand corner, then go to Security Credentials and scroll down to Access Keys. Click Create Access Key.</p> <p>Check the box next to \u201cI understand creating a root access key is not a best practice, but I still want to create one.\u201d and click Create Access Key.</p> <p>Save the access key and secret somewhere safe; you won\u2019t be able to access the secret once you leave this page.</p>"},{"location":"quickstart_2_aws_infra_setup/#set-up-environment-variables-for-aws-cli-access","title":"Set up environment variables for AWS CLI access","text":"<p>Now set your environment variables with the key and secret you just created:</p> <pre><code>export AWS_ACCESS_KEY_ID=EXAMPLE_ACCESS_KEY_ID\nexport AWS_SECRET_ACCESS_KEY=EXAMPLE_SECRET_ACCESS_KEY\nexport AWS_SESSION_TOKEN=EXAMPLE_SESSION_TOKEN # Optional. If you are using Multi-Factor Auth.\n</code></pre>"},{"location":"quickstart_2_aws_infra_setup/#build-cloudformation-stack-for-k0rdent-and-capa","title":"Build CloudFormation stack for k0rdent and CAPA","text":"<p>Now you\u2019ll need to create the Cloudformation stack that k0rdent will use to interact with AWS. You can do this with the clusterawsadm tool:</p> <pre><code>clusterawsadm bootstrap iam create-cloudformation-stack\n</code></pre> <p>This stack creates Roles and Policies we\u2019re going to need later. This is an example of the output:</p> <pre><code>Attempting to create AWS CloudFormation stack cluster-api-provider-aws-sigs-k8s-io\n\nFollowing resources are in the stack:\n\nResource                  |Type                                                                                  |Status\nAWS::IAM::InstanceProfile |control-plane.cluster-api-provider-aws.sigs.k8s.io                                    |CREATE_COMPLETE\nAWS::IAM::InstanceProfile |controllers.cluster-api-provider-aws.sigs.k8s.io                                      |CREATE_COMPLETE\nAWS::IAM::InstanceProfile |nodes.cluster-api-provider-aws.sigs.k8s.io                                            |CREATE_COMPLETE\nAWS::IAM::ManagedPolicy   |arn:aws:iam::743175908171:policy/control-plane.cluster-api-provider-aws.sigs.k8s.io   |CREATE_COMPLETE\nAWS::IAM::ManagedPolicy   |arn:aws:iam::743175908171:policy/nodes.cluster-api-provider-aws.sigs.k8s.io           |CREATE_COMPLETE\nAWS::IAM::ManagedPolicy   |arn:aws:iam::743175908171:policy/controllers.cluster-api-provider-aws.sigs.k8s.io     |CREATE_COMPLETE\nAWS::IAM::ManagedPolicy   |arn:aws:iam::743175908171:policy/controllers-eks.cluster-api-provider-aws.sigs.k8s.io |CREATE_COMPLETE\nAWS::IAM::Role            |control-plane.cluster-api-provider-aws.sigs.k8s.io                                    |CREATE_COMPLETE\nAWS::IAM::Role            |controllers.cluster-api-provider-aws.sigs.k8s.io                                      |CREATE_COMPLETE\nAWS::IAM::Role            |eks-controlplane.cluster-api-provider-aws.sigs.k8s.io                                 |CREATE_COMPLETE\nAWS::IAM::Role            |nodes.cluster-api-provider-aws.sigs.k8s.io                                            |CREATE_COMPLETE\n</code></pre>"},{"location":"quickstart_2_aws_infra_setup/#create-aws-user","title":"Create AWS user","text":"<p>Now let\u2019s go ahead and create a user under whose identity k0rdent will take actions on AWS. Go to the console at https://aws.amazon.com and sign in. From there, follow these steps:</p> <ol> <li>Click your name in the upper-right corner.</li> <li>Click Credentials.</li> <li>On the left, click Users-&gt;Create New User.</li> <li>Enter a name for the user, then click Next.</li> <li> <p>Click Attach Policies Directly and use the search box to add the following policies:     <pre><code>control-plane.cluster-api-provider-aws.sigs.k8s.io\ncontrollers.cluster-api-provider-aws.sigs.k8s.io\nnodes.cluster-api-provider-aws.sigs.k8s.io\n</code></pre>     Note: if you\u2019re using the search, you may have to add these one at a time, clicking Next to move on, then Previous to come back and add additional policies.</p> <p>Once you\u2019ve added all three policies, click Create User.</p> </li> <li> <p>Click the user. </p> </li> <li>Click the Security Credentials tab. </li> <li>Scroll down to Access Keys and click Create Access Key. Choose Command Line Interface (CLI) and the \u201cI understand the above recommendation and want to proceed to create an access key.\u201d checkbox, then click Next, then Create Access Key.</li> <li>Click Download .CSV file so you don\u2019t lose the secret key.  </li> </ol>"},{"location":"quickstart_2_aws_infra_setup/#export-aws-credentials-for-k0rdent","title":"Export AWS credentials for k0rdent","text":"<p>Now we can finally install the Credentials into k0rdent.  Go ahead and set the environment variables to match the access key and secret that you just created:</p> <pre><code>export AWS_REGION=us-east-2\nexport AWS_ACCESS_KEY_ID=\"YOUR_ACCESS_KEY_ID\"\nexport AWS_SECRET_ACCESS_KEY=\"YOUR_SECRET_ACCESS_KEY\"\n</code></pre>"},{"location":"quickstart_2_aws_infra_setup/#create-k0rdent-credentials-objects","title":"Create k0rdent credentials objects","text":"<p>Now go ahead and create the credentials objects:</p> <pre><code>make setup-aws-creds\n</code></pre> <p>This command creates the Credential objects that templates will reference so that they can interact with the AWS infrastructure.</p> <p>It takes a few seconds for the credentials to be completely ready, so check on the status with:</p> <pre><code>PATH=$PATH:./bin kubectl -n hmc-system get credentials aws-cluster-identity-cred\n</code></pre> <p>When they\u2019re ready, you\u2019ll see the READY state is true, as in:</p> <pre><code>NAME                        READY   DESCRIPTION\naws-cluster-identity-cred   true    Basic AWS credentials\n</code></pre> <p>Now we\u2019re ready to go ahead and start working with k0rdent to deploy managed clusters on AWS.</p>"},{"location":"quickstart_3_deploy_managed_cluster_aws/","title":"QuickStart 3 - Deploy managed clusters on AWS","text":"<p>k0rdent's template-driven system includes <code>ClusterTemplates</code>, for creating and lifecycle managing clusters on infrastructures, and <code>ServiceTemplates</code>, for installing and lifecycle managing services on them.</p> <p>Right now, what we're interested in is using a ClusterTemplate to describe the managed clusters we want k0rdent to create on AWS. In the real world, this work would probably be done by a Platform Team Lead, because it requires admin access to k0rdent's Management Cluster.</p> <p>Here is our ClusterTemplate:</p> <pre><code>apiVersion: hmc.mirantis.com/v1alpha1\nkind: ClusterTemplate\nmetadata:\n  name: demo-aws-standalone-cp-0.0.1\n  namespace: hmc-system\nspec:\n  helm:\n    chartSpec:\n      chart: demo-aws-standalone-cp\n      version: 0.0.1\n      interval: 10m0s\n      sourceRef:\n        kind: HelmRepository\n        name: 2a-demos\n  providers:\n  - bootstrap-k0smotron\n  - control-plane-k0smotron\n  - infrastructure-aws\n  providerContracts:\n    bootstrap-k0smotron: v1beta1\n    control-plane-k0smotron: v1beta1\n    infrastructure-aws: v1beta2\n---\napiVersion: hmc.mirantis.com/v1alpha1\nkind: ClusterTemplateChain\nmetadata:\n  name: demo-aws-standalone-cp-0.0.1\n  namespace: hmc-system\nspec:\n  supportedTemplates:\n    - name: demo-aws-standalone-cp-0.0.1\n</code></pre> <p>This YAML file includes two documents. The first, the ClusterTemplate, provides information that will be used to create the cluster. It specifies the Helm chart information, as well as CAPI providers and information about them. The second document, the ClusterTemplateChain, pertains to how k0rdent aligns different templates to enable coordinated management within guardrails that enforce best practices (read all about it in the Administration Guide).</p>"},{"location":"quickstart_3_deploy_managed_cluster_aws/#install-clustertemplate","title":"Install ClusterTemplate","text":"<p>Before we can use this template, we need to install it into the management cluster. You can do this manually by applying the YAML file to the cluster, but for now, let\u2019s use the convenience script:</p> <pre><code>make apply-clustertemplate-demo-aws-standalone-cp-0.0.1\n</code></pre> <p>Note: Applying the ClusterTemplate doesn't actually create a managed cluster. What it does is create the ClusterTemplate object k0rdent will use to enable creation and lifecycle management of this kind of cluster.</p>"},{"location":"quickstart_3_deploy_managed_cluster_aws/#view-clustertemplates","title":"View ClusterTemplates","text":"<p>When we installed k0rdent earlier, many templates got set up this way. We can see them with kubectl:</p> <pre><code>kubectl -n hmc-system get clustertemplate\n</code></pre> <p>You should see a list of ClusterTemplates:</p> <pre><code>NAME                           VALID\naws-eks-0-0-2                  true\naws-hosted-cp-0-0-3            true\naws-standalone-cp-0-0-4        true\nazure-hosted-cp-0-0-3          true\nazure-standalone-cp-0-0-4      true\ndemo-aws-standalone-cp-0.0.1   false\nvsphere-hosted-cp-0-0-3        true\nvsphere-standalone-cp-0-0-3    true\n</code></pre> <p>These are all the cluster and cloud/infrastructure types k0rdent lets us deploy and manage 'out of the box.'</p>"},{"location":"quickstart_3_deploy_managed_cluster_aws/#examine-a-managedcluster","title":"Examine a ManagedCluster","text":"<p>Actually deploying a cluster requires creating another kind of object for k0rdent: a <code>ManagedCluster</code>. Here's an example:</p> <pre><code>apiVersion: hmc.mirantis.com/v1alpha1\nkind: ManagedCluster\nmetadata:\n  name: my-aws-managedcluster1\n  namespace: hmc-system\nspec:\n  template: aws-standalone-cp-0-0-4\n  credential: cluster-identity-cred\n  config:\n    region: us-west-2\n    controlPlane:\n      instanceType: t3.small\n    worker:\n      instanceType: t3.small\n</code></pre> <p>The ManagedCluster object ties a ClusterTemplate together with instance specifics (e.g., What do you want to call this cluster? What k0rdent namespace should this cluster live in?) and infrastructure details (e.g., what AWS region do we want to deploy into? What instance type(s) should k0rdent use for control plane and worker nodes?), among other info, including the credentials we just created \u2014 required to deploy this instance.</p> <p>Again, we could simply apply this template to the management cluster, like this:</p> <pre><code>kubectl apply -f my-aws-managedcluster1.yaml\n</code></pre>"},{"location":"quickstart_3_deploy_managed_cluster_aws/#create-two-clusters-on-aws","title":"Create two clusters on AWS","text":"<p>But instead we\u2019ll use the Makefile to create two clusters:</p> <pre><code>make apply-managed-cluster-aws-test1-0.0.1\nmake apply-managed-cluster-aws-test2-0.0.1\n</code></pre> <p>Note that it can take 5-10 minutes for the cluster to finish provisioning. You can follow the provisioning process:</p> <pre><code>kubectl -n hmc-system get managedcluster.hmc.mirantis.com test1 --watch\n</code></pre> <p>You can also use the Makefile to show the status and rollout of the cluster as k0rdent sees it:</p> <pre><code>make watch-aws-test1\n</code></pre> <p>When the cluster has been completely deployed, you\u2019ll see a message that says:</p> <pre><code>NAME                   READY   STATUS\nhmc-system-aws-test1   True    ManagedCluster is ready\n</code></pre>"},{"location":"quickstart_3_deploy_managed_cluster_aws/#obtain-kubeconfigs","title":"Obtain kubeconfigs","text":"<p>Once the deployment is done, you can go ahead and grab the KUBECONFIGs:</p> <pre><code>make get-kubeconfig-aws-test1\nmake get-kubeconfig-aws-test2\n</code></pre> <p>The script puts the KUBECONFIG for a cluster admin in the kubeconfigs folder.</p> <p>At this point you have two Kubernetes clusters created by k0rdent, and because they\u2019re just normal Kubernetes clusters, you can access them through kubectl just like any other clusters you\u2019d create:</p> <pre><code>KUBECONFIG=\"kubeconfigs/hmc-system-aws-test1.kubeconfig\" kubectl get pods -A\nKUBECONFIG=\"kubeconfigs/hmc-system-aws-test2.kubeconfig\" kubectl get pods -A\n</code></pre> <p>Congratulations, you\u2019ve created your first clusters with k0rdent! Now we invite you to proceed to our Tutorials to see how k0rdent is used, day to day, at scale.</p>"},{"location":"tutorial_1_upgrade_single_cluster/","title":"Tutorial 1 - Upgrade a single cluster","text":"<p>k0rdent lets you easily upgrade a managed cluster by changing the ClusterTemplate that defines it or applying a new ClusterTemplate to it.</p> <p>At the conclusion of QuickStart 3 we deployed two clusters on AWS, using version v1.31.1+k0s.1 of k0s Kubernetes, as specified in the <code>demo-aws-standalone-cp-0.0.1</code> template. Now we\u2019ll upgrade one of our clusters (aws-test1) to v1.31.2+k0s.0 by applying the ClusterTemplate named <code>demo-aws-standalone-cp-0.0.2</code>.</p>"},{"location":"tutorial_1_upgrade_single_cluster/#examine-the-upgrade-clustertemplate","title":"Examine the upgrade ClusterTemplate","text":"<p>The first thing we need to do is install the ClusterTemplate for the upgrade, which looks like this:</p> <pre><code>apiVersion: hmc.mirantis.com/v1alpha1\nkind: ClusterTemplate\nmetadata:\n  name: demo-aws-standalone-cp-0.0.2\n  namespace: hmc-system\nspec:\n  helm:\n    chartSpec:\n      chart: demo-aws-standalone-cp\n      version: 0.0.2\n      interval: 10m0s\n      sourceRef:\n        kind: HelmRepository\n        name: 2a-demos\n  providers:\n  - bootstrap-k0smotron\n  - control-plane-k0smotron\n  - infrastructure-aws\n  providerContracts:\n    bootstrap-k0smotron: v1beta1\n    control-plane-k0smotron: v1beta1\n    infrastructure-aws: v1beta2\n---\napiVersion: hmc.mirantis.com/v1alpha1\nkind: ClusterTemplateChain\nmetadata:\n  name: demo-aws-standalone-cp-0.0.2\n  namespace: hmc-system\nspec:\n  supportedTemplates:\n    - name: demo-aws-standalone-cp-0.0.1\n      availableUpgrades:\n        - name: demo-aws-standalone-cp-0.0.2\n    - name: demo-aws-standalone-cp-0.0.2\n</code></pre> <p>As you can see, this template is very similar to the original ClusterTemplate, but the ClusterTemplateChain sub-document tells k0rdent that the demo-aws-standalone-cp-0.0.2 template is an upgrade from demo-aws-standalone-cp-0.0.1.</p>"},{"location":"tutorial_1_upgrade_single_cluster/#install-the-upgrade-clustertemplate","title":"Install the upgrade ClusterTemplate","text":"<p>Now let\u2019s use the Makefile to install <code>demo-aws-standalone-cp-0.0.2</code> on the management cluster:</p> <pre><code>make apply-clustertemplate-demo-aws-standalone-cp-0.0.2\n</code></pre> <p>You\u2019ll see that it creates the appropriate objects:</p> <pre><code>clustertemplate.hmc.mirantis.com/demo-aws-standalone-cp-0.0.2 created\nclustertemplatechain.hmc.mirantis.com/demo-aws-standalone-cp-0.0.2 created\n</code></pre>"},{"location":"tutorial_1_upgrade_single_cluster/#confirm-the-upgrade-is-available","title":"Confirm the upgrade is available","text":"<p>Once we\u2019ve installed this template, k0rdent knows the upgrade is available, which we can see by looking for available upgrades:</p> <pre><code>make get-avaliable-upgrades\n</code></pre> <p>You should see a result like this. k0rdent traces the ClusterTemplateChain and determines that this upgrade can apply to both of your clusters:</p> <pre><code>Cluster hmc-system-aws-test1 available upgrades:\n        - demo-aws-standalone-cp-0.0.2\n\nCluster hmc-system-aws-test2 available upgrades:\n        - demo-aws-standalone-cp-0.0.2\n</code></pre>"},{"location":"tutorial_1_upgrade_single_cluster/#apply-the-upgrade-to-one-cluster","title":"Apply the upgrade to one cluster","text":"<p>Now let\u2019s go ahead and apply the upgrade to one of our clusters:</p> <pre><code>make apply-managed-cluster-aws-test1-0.0.2\n</code></pre>"},{"location":"tutorial_1_upgrade_single_cluster/#monitor-upgrade-rollout","title":"Monitor upgrade rollout","text":"<p>k0rdent automatically applies upgrades to k0s-based clusters using an extremely-reliable, workload-sparing rolling process. We can monitor progress and watch how new machines are created and old machines are deleted:</p> <pre><code>PATH=$PATH:./bin kubectl -n hmc-system get machines -w\n</code></pre> <p>Note that control plane nodes for k0s clusters are upgraded in place (check the version field) without provisioning new machines.</p> <p>You can also see old nodes are drained and new nodes are attached:</p> <pre><code>KUBECONFIG=\"kubeconfigs/hmc-system-aws-test1.kubeconfig\" PATH=$PATH:./bin kubectl get node -w\n</code></pre>"},{"location":"tutorial_1_upgrade_single_cluster/#take-aways","title":"Take aways","text":"<p>k0rdent not only lets you perform upgrades in a declarative way, but via ClusterTemplateChains, implements guardrail mechanisms that users can be made aware of available upgrades, and ensure that upgrades are processed safely, in proper order. k0s cluster rolling upgrades are efficient and avoid workload impacts.</p> <p>In Tutorial 2 - Install a ServiceTemplate into a cluster we'll begin exploring ServiceTemplates \u2014 and see how services can be orchestrated onto clusters, creating complete platforms.</p>"},{"location":"tutorial_2_install_service_template_single_cluster/","title":"Tutorial 2 - Install a ServiceTemplate into a single cluster","text":"<p>Clusters are only useful if developers can build on them, so let\u2019s go ahead and look at that process. </p> <p>Just as you can create clusters by referencing templates, you can use ServiceTemplates to create workloads and other services in a managed cluster. These services can be something that\u2019s been prepared and made available by the company or by a vendor, or they can be part of an application built by the project team.</p>"},{"location":"tutorial_2_install_service_template_single_cluster/#examine-a-servicetemplate","title":"Examine a ServiceTemplate","text":"<p>In this case, we\u2019re going to install a ServiceTemplate that represents a deployment of Nginx Ingress to the managed cluster. The template looks like this:</p> <pre><code>apiVersion: hmc.mirantis.com/v1alpha1\nkind: ServiceTemplate\nmetadata:\n  name: demo-ingress-nginx-4.11.0\n  namespace: hmc-system\nspec:\n  helm:\n    chartSpec:\n      chart: demo-ingress-nginx\n      version: 4.11.0\n      interval: 10m0s\n      sourceRef:\n        kind: HelmRepository\n        name: 2a-demos\n---\napiVersion: hmc.mirantis.com/v1alpha1\nkind: ServiceTemplateChain\nmetadata:\n  name: demo-ingress-nginx-4.11.0\n  namespace: hmc-system\nspec:\n  supportedTemplates:\n    - name: demo-ingress-nginx-4.11.0\n</code></pre> <p>As you can see, the template specifies what you need to deploy an app into the Kubernetes cluster: Helm chart information. Also, we\u2019ve got the ServiceTemplateChain, which is similar to the ClusterTemplateChain in that it will specify upgrades (when appropriate).</p>"},{"location":"tutorial_2_install_service_template_single_cluster/#install-the-servicetemplate","title":"Install the ServiceTemplate","text":"<p>As before, we\u2019ll start by installing the template into the management cluster so that k0rdent can use it to install to any of the managed clusters:</p> <pre><code>make apply-servicetemplate-demo-ingress-nginx-4.11.0\n</code></pre>"},{"location":"tutorial_2_install_service_template_single_cluster/#apply-the-servicetemplate","title":"Apply the ServiceTemplate","text":"<p>Then we\u2019ll apply the ServiceTemplate to the aws-test2 cluster by referencing it in the cluster's <code>ManagedCluster</code> YAML file:</p> <pre><code>apiVersion: hmc.mirantis.com/v1alpha1\nkind: ManagedCluster\nmetadata:\n  name: ${NAMESPACE}-aws-${CLUSTERNAME}\n  namespace: ${NAMESPACE}\nspec:\n  template: demo-aws-standalone-cp-0.0.1\n  credential: aws-cluster-identity-cred\n  config:\n    region: us-east-2\n    publicIP: true\n    controlPlaneNumber: 1\n    workersNumber: 2\n    controlPlane:\n      instanceType: t3.small\n    worker:\n      instanceType: t3.small\n  services:\n    - template: demo-ingress-nginx-4.11.0\n      name: ingress-nginx\n      namespace: ingress-nginx\n</code></pre>"},{"location":"tutorial_2_install_service_template_single_cluster/#examine-the-template-placeholders","title":"Examine the template placeholders","text":"<p>Notice that there are several placeholders in this template, in the form of ${PLACEHOLDERNAME}. k0rdent's template system propagates configuration specifics to populate templates correctly in context \u2014 eliminating manual changes, empowering reuse while preventing template proliferation, and helping you maintain 'single sources of truth'.</p> <p>For example, note that we're specifying an entire cluster in this <code>ManagedCluster' file. When we apply this file, we\u2019re counting on k0rdent to reconcile the difference(s) between the current state of the cluster and the desired state. Of course, these differences include the fact that we're adding services, so our new</code>ManagedCluster` config references the ServiceTemplate for the service we're adding (NGINX) and states the namespace NGINX should be installed in.</p>"},{"location":"tutorial_2_install_service_template_single_cluster/#apply-the-servicetemplate-via-the-managedcluster","title":"Apply the ServiceTemplate via the ManagedCluster","text":"<p>Let\u2019s go ahead and apply this adjusted <code>ManagedCluster</code> to install it in the management cluster and install the service in the selected target cluster:</p> <pre><code>make apply-managed-cluster-aws-test2-0.0.1-ingress\n</code></pre> <p>You can watch for it to be installed:</p> <pre><code>watch KUBECONFIG=\"kubeconfigs/hmc-system-aws-test2.kubeconfig\" PATH=$PATH:./bin kubectl get pods -n ingress-nginx\n</code></pre> <p>When it\u2019s running, you\u2019ll see the pod:</p> <pre><code>NAME                                        READY   STATUS    RESTARTS   AGE\ningress-nginx-controller-86bd747cf9-dxbgq   1/1     Running   0          55s\n</code></pre> <p>This technique becomes even more powerful when you want to install new services into multiple clusters.</p>"},{"location":"tutorial_3_install_service_template_into_multiple_clusters/","title":"Tutorial 3 - Install ServiceTemplate into multiple clusters","text":"<p>Now we\u2019re going to look at installing a ServiceTemplate into multiple Clusters. k0rdent lets us automate installation of services at scale (potentially at huge scale) without requiring us to reference service additions in the individual <code>ManagedCluster</code> resources for each cluster we want to change.</p> <p>If you\u2019ve been following along with QuickStarts 1-3 and prior tutorials, you should have two managed clusters to work with (on AWS). We\u2019re going to use ServiceTemplates to install Kyverno on both of them \u2014 forming the core of a solution for policy-as-code enforcement.</p>"},{"location":"tutorial_3_install_service_template_into_multiple_clusters/#examine-the-servicetemplate","title":"Examine the ServiceTemplate","text":"<p>As before, we\u2019ll start with a ServiceTemplate:</p> <pre><code>apiVersion: hmc.mirantis.com/v1alpha1\nkind: ServiceTemplate\nmetadata:\n  name: demo-kyverno-3.2.6\n  namespace: hmc-system\nspec:\n  helm:\n    chartSpec:\n      chart: demo-kyverno\n      version: 3.2.6\n      interval: 10m0s\n      sourceRef:\n        kind: HelmRepository\n        name: 2a-demos\n---\napiVersion: hmc.mirantis.com/v1alpha1\nkind: ServiceTemplateChain\nmetadata:\n  name: demo-kyverno-3.2.6\n  namespace: hmc-system\nspec:\n  supportedTemplates:\n    - name: demo-kyverno-3.2.6\n</code></pre>"},{"location":"tutorial_3_install_service_template_into_multiple_clusters/#install-the-servicetemplate-into-k0rdent","title":"Install the ServiceTemplate into k0rdent","text":"<p>As you can see, there\u2019s nothing particularly special about this template; it looks like the other base templates we\u2019ve been using.  Let\u2019s go ahead and install it into k0rdent:</p> <pre><code>make apply-servicetemplate-demo-kyverno-3.2.6\n</code></pre> <p>You can see it installed in the system:</p> <pre><code>PATH=$PATH:./bin kubectl -n hmc-system get servicetemplates\n</code></pre> <p>You should be able to see that the template is valid:</p> <pre><code>NAME                        VALID\ndemo-ingress-nginx-4.11.0   true\ndemo-kyverno-3.2.6          true &lt;-- This is the new template\ningress-nginx-4-11-0        true\ningress-nginx-4-11-3        true\nkyverno-3-2-6               true\n</code></pre>"},{"location":"tutorial_3_install_service_template_into_multiple_clusters/#define-a-multiclusterservice-to-deploy-the-service-on-multiple-clusters","title":"Define a MultiClusterService to deploy the service on multiple clusters","text":"<p>Instead of always needing to reference a ServiceTemplate in individual ManagedClusters, k0rdent gives us another abstraction for installing ServiceTemplates on multiple target clusters. </p> <p>This is called a <code>MultiClusterService</code>, and it uses a <code>clusterSelector</code> field. Here's an example:</p> <pre><code>apiVersion: hmc.mirantis.com/v1alpha1\nkind: MultiClusterService\nmetadata:\n  name: global-kyverno\nspec:\n  servicesPriority: 1000\n  clusterSelector:\n    matchLabels:\n      app.kubernetes.io/managed-by: Helm\n  services:\n    - template: kyverno-3-2-6\n      name: kyverno\n      namespace: kyverno\n</code></pre> <p>As you can see, we\u2019re referencing the kyverno-3-2-6 ServiceTemplate we installed in the last step, then specifying that we want it installed in all clusters that are managed by Helm. Clearly, this is very flexible: we can filter for clusters using many different labels, as well as combinations of labels.</p>"},{"location":"tutorial_3_install_service_template_into_multiple_clusters/#apply-the-multiclusterservice-template-to-install-services-on-clusters","title":"Apply the MultiClusterService template to install services on clusters","text":"<p>Now we can apply that MultiClusterService template:</p> <pre><code>make apply-multiclusterservice-global-kyverno\n</code></pre> <p>We can see that Kyverno is being installed in both clusters:</p> <pre><code>KUBECONFIG=\"kubeconfigs/hmc-system-aws-test1.kubeconfig\" kubectl get pods -n kyverno\nKUBECONFIG=\"kubeconfigs/hmc-system-aws-test2.kubeconfig\" kubectl get pods -n kyverno\n</code></pre> <p>Note that it may take 1-2 minutes before Kyverno begins installing.</p>"},{"location":"tutorial_3_install_service_template_into_multiple_clusters/#next-up-k0rdent-workflows","title":"Next up: k0rdent workflows","text":"<p>In our next set of tutorials, we start looking at ways k0rdent helps Platform Architects and Platform Engineering Teams deliver innovation across their organizations. Specifically, we're going to show you (hands-on) how Platform Architects can:</p> <ul> <li>Approve ClusterTemplates and ServiceTemplates for use by others</li> <li>Safely share credentials required for others to use these templates</li> <li>Place constraints on how templates can be used (e.g., only within specific namespaces)</li> </ul> <p>We'll then go on to show how Platform Leads and other 'innovation consumers' can use k0rdent safely within these critical guardrails.   </p>"},{"location":"why_k0rdent/","title":"Why k0rdent?","text":"<p>With the increasing complexity of modern systems, it has become more and more necessary to provide a way for administrators to manage that complexity while still providing the means for developers to get their jobs done as efficiently as possible.  Enter platforms. These frameworks or environments provide the foundation and tools for developing, deploying, and managing applications, services, or systems, enabling users to focus on their specific tasks or goals while abstracting away the underlying complexities.</p> <p>As the need for platform engineering, the practice of designing, building, and maintaining these platforms, becomes evident, so do some of the challenges of creating a truly functional platform engineering environment. Assembling, integrating, deploying, and managing Kubernetes clusters is straightforward in theory, but where companies may have once had a single multi-purpose platform, the current trend is to implement many more purpose-dedicated, simpler platforms. While this makes managing each platform easier, you\u2019re left with a sum that\u2019s more than its parts, both in capability and complexity. Once you add in multiple clouds, differing infrastructures, and the need to prepare those infrastructures to host workloads, platform engineering moves from being a task on an administrator\u2019s plate to being an entire discipline.</p> <p>The solution must be answerable to real world needs. This moves beyond simple resilience and availability to awareness of security and compliance requirements, including access management and sharing. Platform engineers need to be able to compose platforms\u2013for example, Kubernetes, beach-head services such as CI/CD, and any other dependencies workloads require\u2013in simple, repeatable ways. They also need to be able to safely and flexibly share access and artifacts with platform leads and other platform 'consumers/users.' On top of that, platforms must enable visibility into both the infrastructure and applications, including both performance and cost monitoring and ensuring platform integrity with state monitoring and continuous reconciliation, all while simplifying platform operations for Day 2 and beyond.</p> <p>All of these functionalities are available in open source. Kubernetes is the most obvious substrate, of course, providing tools for not only container orchestration, but also custom operators. Fortunately, there are optimized distros of Kubernetes such as k0s, and Kubernetes itself can be orchestrated using the Kubernetes Cluster API (CAPI), which can both manage clouds and infrastructure and assemble, create and lifecycle manage clusters on those infrastructures. Add open source tools such as Helm and other package managers to help manage deployment, upgrade, and removal of applications, and you have a complete platform engineering solution.</p> <p>Of course, getting all of the relevant pieces to work together\u2013particularly over multiple infrastructures\u2013isn\u2019t simple or straightforward. That\u2019s why you need k0rdent. k0rdent puts all of these pieces together so you don\u2019t have to.</p>"}]}